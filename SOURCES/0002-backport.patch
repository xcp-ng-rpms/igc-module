
### Backport code to kernel 4.19 by removing nerwer code that does not work
### in the older kernel and cange functions back to older ones that work in 4.19
### 	remove ETHTOOL_COALESCE_USECS
### 	remove TC_SETUP_QDISC_TAPRIO
### 	change net_prefetch to prefetch
### 	change netdev_xmit_more to skb->xmit_more
### 	change DPM_FLAG_NO_DIRECT_COMPLETE to DPM_FLAG_NEVER_SKIP
###	add new needed skbuff code
###
### Change MTU change notice to netdev_info becuase it's not debugging
###
###
### Change gettimex64 back to gettime64

--- a/igc_main.c	2023-07-27 06:44:44.000000000 +0000
+++ b/igc_main.c	2023-08-01 02:04:34.725132607 +0000
@@ -10,6 +10,7 @@
 #include <linux/ip.h>
 #include <linux/pm_runtime.h>
 #include <linux/pci.h>
+#include <linux/skbuff.h>
 #include <net/pkt_sched.h>
 
 #include <net/ipv6.h>
@@ -67,6 +68,11 @@
 	latency_invalid = 255
 };
 
+static inline bool skb_csum_is_sctp(struct sk_buff *skb)
+{
+        return skb->csum_not_inet;
+}
+
 void igc_reset(struct igc_adapter *adapter)
 {
 	struct net_device *dev = adapter->netdev;
@@ -1262,7 +1268,8 @@
 	/* Make sure there is space in the ring for the next send. */
 	igc_maybe_stop_tx(tx_ring, DESC_NEEDED);
 
-	if (netif_xmit_stopped(txring_txq(tx_ring)) || !netdev_xmit_more()) {
+	if (netif_xmit_stopped(txring_txq(tx_ring)) || !skb->xmit_more) {
+
 		writel(i, tx_ring->tail);
 	}
 
@@ -1691,7 +1698,7 @@
 	struct sk_buff *skb;
 
 	/* prefetch first cache line of first page */
-	net_prefetch(va);
+	prefetch(va);
 
 	/* build an skb around the page buffer */
 	skb = build_skb(va - IGC_SKB_PAD, truesize);
@@ -1727,7 +1734,7 @@
 	struct sk_buff *skb;
 
 	/* prefetch first cache line of first page */
-	net_prefetch(va);
+	prefetch(va);
 
 	/* allocate a skb to store the frags */
 	skb = napi_alloc_skb(&rx_ring->q_vector->napi, IGC_RX_HDR_LEN);
@@ -1743,7 +1750,8 @@
 	/* Determine available headroom for copy */
 	headlen = size;
 	if (headlen > IGC_RX_HDR_LEN)
-		headlen = eth_get_headlen(skb->dev, va, IGC_RX_HDR_LEN);
+		headlen = eth_get_headlen(va, IGC_RX_HDR_LEN);
+
 
 	/* align pull length to size of long to optimize memcpy performance */
 	memcpy(__skb_put(skb, headlen), va, ALIGN(headlen, sizeof(long)));
@@ -4025,7 +4033,7 @@
 	if (netif_running(netdev))
 		igc_down(adapter);
 
-	netdev_dbg(netdev, "changing MTU from %d to %d\n", netdev->mtu, new_mtu);
+	netdev_info(netdev, "changing MTU from %d to %d\n", netdev->mtu, new_mtu);
 	netdev->mtu = new_mtu;
 
 	if (netif_running(netdev))
@@ -4856,65 +4864,6 @@
 	return 0;
 }
 
-static bool is_base_time_past(ktime_t base_time, const struct timespec64 *now)
-{
-	struct timespec64 b;
-
-	b = ktime_to_timespec64(base_time);
-
-	return timespec64_compare(now, &b) > 0;
-}
-
-static bool validate_schedule(struct igc_adapter *adapter,
-			      const struct tc_taprio_qopt_offload *qopt)
-{
-	int queue_uses[IGC_MAX_TX_QUEUES] = { };
-	struct timespec64 now;
-	size_t n;
-
-	if (qopt->cycle_time_extension)
-		return false;
-
-	igc_ptp_read(adapter, &now);
-
-	/* If we program the controller's BASET registers with a time
-	 * in the future, it will hold all the packets until that
-	 * time, causing a lot of TX Hangs, so to avoid that, we
-	 * reject schedules that would start in the future.
-	 */
-	if (!is_base_time_past(qopt->base_time, &now))
-		return false;
-
-	for (n = 0; n < qopt->num_entries; n++) {
-		const struct tc_taprio_sched_entry *e, *prev;
-		int i;
-
-		prev = n ? &qopt->entries[n - 1] : NULL;
-		e = &qopt->entries[n];
-
-		/* i225 only supports "global" frame preemption
-		 * settings.
-		 */
-		if (e->command != TC_TAPRIO_CMD_SET_GATES)
-			return false;
-
-		for (i = 0; i < adapter->num_tx_queues; i++)
-			if (e->gate_mask & BIT(i)) {
-				queue_uses[i]++;
-
-				/* There are limitations: A single queue cannot
-				 * be opened and closed multiple times per cycle
-				 * unless the gate stays open. Check for it.
-				 */
-				if (queue_uses[i] > 1 &&
-				    !(prev->gate_mask & BIT(i)))
-					return false;
-			}
-	}
-
-	return true;
-}
-
 static int igc_tsn_enable_launchtime(struct igc_adapter *adapter,
 				     struct tc_etf_qopt_offload *qopt)
 {
@@ -4931,111 +4880,12 @@
 	return igc_tsn_offload_apply(adapter);
 }
 
-static int igc_save_qbv_schedule(struct igc_adapter *adapter,
-				 struct tc_taprio_qopt_offload *qopt)
-{
-	bool queue_configured[IGC_MAX_TX_QUEUES] = { };
-	u32 start_time = 0, end_time = 0;
-	size_t n;
-	int i;
-
-	if (!qopt->enable) {
-		adapter->base_time = 0;
-		return 0;
-	}
-
-	if (qopt->base_time < 0)
-		return -ERANGE;
-
-	if (adapter->base_time)
-		return -EALREADY;
-
-	if (!validate_schedule(adapter, qopt))
-		return -EINVAL;
-
-	adapter->cycle_time = qopt->cycle_time;
-	adapter->base_time = qopt->base_time;
-
-	for (n = 0; n < qopt->num_entries; n++) {
-		struct tc_taprio_sched_entry *e = &qopt->entries[n];
-
-		end_time += e->interval;
-
-		/* If any of the conditions below are true, we need to manually
-		 * control the end time of the cycle.
-		 * 1. Qbv users can specify a cycle time that is not equal
-		 * to the total GCL intervals. Hence, recalculation is
-		 * necessary here to exclude the time interval that
-		 * exceeds the cycle time.
-		 * 2. According to IEEE Std. 802.1Q-2018 section 8.6.9.2,
-		 * once the end of the list is reached, it will switch
-		 * to the END_OF_CYCLE state and leave the gates in the
-		 * same state until the next cycle is started.
-		 */
-		if (end_time > adapter->cycle_time ||
-		    n + 1 == qopt->num_entries)
-			end_time = adapter->cycle_time;
-
-		for (i = 0; i < adapter->num_tx_queues; i++) {
-			struct igc_ring *ring = adapter->tx_ring[i];
-
-			if (!(e->gate_mask & BIT(i)))
-				continue;
-
-			/* Check whether a queue stays open for more than one
-			 * entry. If so, keep the start and advance the end
-			 * time.
-			 */
-			if (!queue_configured[i])
-				ring->start_time = start_time;
-			ring->end_time = end_time;
-
-			queue_configured[i] = true;
-		}
-
-		start_time += e->interval;
-	}
-
-	/* Check whether a queue gets configured.
-	 * If not, set the start and end time to be end time.
-	 */
-	for (i = 0; i < adapter->num_tx_queues; i++) {
-		if (!queue_configured[i]) {
-			struct igc_ring *ring = adapter->tx_ring[i];
-
-			ring->start_time = end_time;
-			ring->end_time = end_time;
-		}
-	}
-
-	return 0;
-}
-
-static int igc_tsn_enable_qbv_scheduling(struct igc_adapter *adapter,
-					 struct tc_taprio_qopt_offload *qopt)
-{
-	struct igc_hw *hw = &adapter->hw;
-	int err;
-
-	if (hw->mac.type != igc_i225)
-		return -EOPNOTSUPP;
-
-	err = igc_save_qbv_schedule(adapter, qopt);
-	if (err)
-		return err;
-
-	return igc_tsn_offload_apply(adapter);
-}
-
 static int igc_setup_tc(struct net_device *dev, enum tc_setup_type type,
 			void *type_data)
 {
 	struct igc_adapter *adapter = netdev_priv(dev);
 
 	switch (type) {
-	case TC_SETUP_QDISC_TAPRIO:
-		return igc_tsn_enable_qbv_scheduling(adapter, type_data);
-
 	case TC_SETUP_QDISC_ETF:
 		return igc_tsn_enable_launchtime(adapter, type_data);
 
@@ -5393,7 +5243,7 @@
 	pcie_print_link_status(pdev);
 	netdev_info(netdev, "MAC: %pM\n", netdev->dev_addr);
 
-	dev_pm_set_driver_flags(&pdev->dev, DPM_FLAG_NO_DIRECT_COMPLETE);
+	dev_pm_set_driver_flags(&pdev->dev, DPM_FLAG_NEVER_SKIP);
 	/* Disable EEE for internal PHY devices */
 	hw->dev_spec._base.eee_enable = false;
 	adapter->flags &= ~IGC_FLAG_EEE;
--- a/igc_ptp.c	2023-07-27 06:44:44.000000000 +0000
+++ b/igc_ptp.c	2023-08-01 01:44:59.252583293 +0000
@@ -83,21 +83,16 @@
 	return 0;
 }
 
-static int igc_ptp_gettimex64_i225(struct ptp_clock_info *ptp,
-				   struct timespec64 *ts,
-				   struct ptp_system_timestamp *sts)
+static int igc_ptp_gettime_i225(struct ptp_clock_info *ptp,
+				   struct timespec64 *ts)
 {
 	struct igc_adapter *igc = container_of(ptp, struct igc_adapter,
 					       ptp_caps);
-	struct igc_hw *hw = &igc->hw;
 	unsigned long flags;
 
 	spin_lock_irqsave(&igc->tmreg_lock, flags);
 
-	ptp_read_system_prets(sts);
-	ts->tv_nsec = rd32(IGC_SYSTIML);
-	ts->tv_sec = rd32(IGC_SYSTIMH);
-	ptp_read_system_postts(sts);
+	igc_ptp_read(igc, ts);
 
 	spin_unlock_irqrestore(&igc->tmreg_lock, flags);
 
@@ -502,7 +497,7 @@
 		adapter->ptp_caps.max_adj = 62499999;
 		adapter->ptp_caps.adjfine = igc_ptp_adjfine_i225;
 		adapter->ptp_caps.adjtime = igc_ptp_adjtime_i225;
-		adapter->ptp_caps.gettimex64 = igc_ptp_gettimex64_i225;
+		adapter->ptp_caps.gettime64 = igc_ptp_gettime_i225;
 		adapter->ptp_caps.settime64 = igc_ptp_settime_i225;
 		adapter->ptp_caps.enable = igc_ptp_feature_enable_i225;
 		break;
--- a/igc_ethtool.c	2023-08-01 01:38:52.683149592 +0000
+++ b/igc_ethtool.c	2023-08-01 01:44:59.256583308 +0000
@@ -1916,7 +1916,6 @@
 }
 
 static const struct ethtool_ops igc_ethtool_ops = {
-	.supported_coalesce_params = ETHTOOL_COALESCE_USECS,
 	.get_drvinfo		= igc_ethtool_get_drvinfo,
 	.get_regs_len		= igc_ethtool_get_regs_len,
 	.get_regs		= igc_ethtool_get_regs,
